{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Fnelf1ZcTMc"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18089,
     "status": "ok",
     "timestamp": 1756475023678,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "_FoVq0OEgHA8",
    "outputId": "830ef0b2-e1fa-4507-e9d3-0bb32f6bca61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30862,
     "status": "ok",
     "timestamp": 1756475095091,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "dFsVao7NeyGm",
    "outputId": "e10b840d-48aa-4c74-aaf2-979418ff0970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/310.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m307.2/310.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU pypdf langchain_community\n",
    "!pip install langchain_chroma langchain_openai --quiet\n",
    "!pip install chromadb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOb4dPaTcJPb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import textwrap\n",
    "import chromadb\n",
    "import io\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import glob\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "from langchain.schema import HumanMessage\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bpJvUHSdOgr"
   },
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497,
     "referenced_widgets": [
      "a33dea6f6340465bb0718c7c45a693c7",
      "cd687be22b4f4acfbd81cb69c50b818e",
      "3b6b6ecdab7b433a876a0816e7ee2a6f",
      "33fe2a51fdaf4c8f82747e96f3b6343b",
      "2db92d6ecdad40008f457ef5dfa0019e",
      "c897a096e08f491dab29521a18332510",
      "4c97dad7950c41a6b43488420780a820",
      "b19c0a7501fd413cac5f99684c5a6fb8",
      "6cd9f8cb2204495eb7baec9ac37fddc6",
      "25bf9665d63c455183f8143df17c4a31",
      "3f3b2a26853c4e3f865556bc1cf255e3",
      "e95858aa194c492e93814f1f92ed9651",
      "147f3598299847d8a1101f519ed847d7",
      "aa9066919be548f2924d251340a445ae",
      "4e2cd2fe954c4dfda09b4086d0dee68c",
      "ebbec36096514f00959cb698cca589b2",
      "00ba7ee94b85484da7b2e2df41119a82",
      "9ddb4c07eb254068acf079142c3fe265",
      "0bd51bc5a7ac4544b8484eedf08cabe4",
      "28ff8088bb3f40658d2441f4c4895a00",
      "136e8db0afdd4a628edf4c029b523782",
      "b346a051b4514112bffadd2df097773d",
      "4ddf2ef7aaed48d0adcc571c95ae31ac",
      "1c2e5df6feca475885931daa4aee53ad",
      "b6daf6b1aa844d6fa4f0431b16aadc0f",
      "35f9a377eec644f399ebd9d7163f31e0",
      "3ef8967cf5024d37899cf04111d2fadb",
      "158eb691d3a1481eb5c184018c039840",
      "820632b7aa2b4086acd0e555f8d29464",
      "cde753ebd6fc43ebbc17ae710340178f",
      "f6c4c3e215b94b1ba3650b068f093287",
      "04665691b3fb4ce59eb89e30c1139325",
      "a855756a2d5e488face2a2c9d87e44f7",
      "8347d220815f43b684cdc8f4e1d3e0ff",
      "a6f765b79cf3425097d2439317c593fb",
      "92d5a7423acb43c58f4c7e07e73c1d2f",
      "d1a4586ed51a4327bc342a476ebcb5c5",
      "f6b14495b72b40df90f6f55510552cdd",
      "8717f9d4ff8247baade230361db96534",
      "a65700a4235345ae989facd658575567",
      "4d9dcc34183347c886c3cf5259508bf9",
      "bf20e326bea843708eddeac21b41b0d5",
      "f3f5d68b63b94246ba6e94211d316e8b",
      "822b3c0119774d5b8dd30b6866738afc",
      "efb4306fd3c24d65b7a2fdb5aed49956",
      "aa17d062de4e47b788de6818e803a249",
      "41071dc5093f4f88a31f9d283eea282e",
      "ea4bc8db65f44a4e9f48dab9af8248de",
      "1b4fdd3c56eb43b68b1c2e6b10a3cb08",
      "31c4f83ac797474db8cc608fc7c13cb4",
      "5b2c9f628ee64fc4a3096c25323adea9",
      "aa683dae46f846398350ef5c5e6c93d7",
      "919b1ce901ca41eaa5db89e4c233e4ce",
      "0de41ec5ed9b43b5b85d0821b7c89f2e",
      "eabd07de7e4a43969df08453797ddcad",
      "02073d61495d4e74b6af61aacbf14dbb",
      "3ae8a34c4d694cfe84efd0e07e1d1279",
      "59f4d08f737547938b9a0f8e115ffa9a",
      "1ca57dc104d144fa86430cfac7e926a1",
      "6fef60cdd7fa466a81d3b68512d4cde7",
      "2fc3264461ca4644b99096e1f39d4bdf",
      "a025bad22c1046bdab5273ab4ef5c76a",
      "46679983baa84ff49c7f0332e5a26199",
      "fff3b2e77477436d9d9976d89c810bc6",
      "03eb5451e4124f988d303a248baf16f4",
      "0facac5a32f440f88a569b1095bab290",
      "2c41cead40974e8ca239b7a716c6b6f9",
      "de575704aea844fca9ccf31acd3a8ac2",
      "eb1d76686de84c4e8ee5cb490a325e11",
      "a46ad22183ef49938e721d43edb13222",
      "98103d5197744a82858a0e3eec067f14",
      "660810bd3ccf4ddd8b0a77a630e53179",
      "ea22bf39e90c433db09faece02812090",
      "1d8b130e756f4b6ca4f943186609d8af",
      "fff563a6788a4b2294b494c37f055773",
      "9cd3acc4e42f4c348f5627c8928a76ac",
      "1e7004e0a1bf421686f9274d5f643a6b",
      "d52a156ca43a49439d743aafa9bd8bae",
      "7c0ae58cec9c4bc88c6993d2705fdcfe",
      "bc812828596e4291b850ee1e5cb13ec1",
      "77f58701e0c0444da5efcde7b52c654b",
      "9528438557e24d15a34b4560bf0b536e",
      "95a3fdc0147646199dc17f4e0073f5d2",
      "70b4994c86cf446491472cd4e67735b7",
      "00293b79cf1c432bba0a733e12a74404",
      "9c8712acd40f43edac07763991b35bdf",
      "88359a05efa1400cae3c137576cbc7a4",
      "aea103c489b34838826cd9116e7d98e9",
      "e9d7af9008d347c0a50e41cc4d52982c",
      "6df74055bed6410a8d1bbcc9837c4870",
      "68297db4a2444af984d6c4378325021d",
      "de841cf151c44f71a4b587e2b3884b8d",
      "21b6cd8a9e4c4d36ac1617585f422d68",
      "fd6ee43297cc4799b7640c0500ab3d3d",
      "e549ec3ae29844f488b69feeacbef667",
      "c36004465c664971a6ea71c418626435",
      "495980bed6d54a02a37f46f2f6d01ea2",
      "ee0bc794fb9b47efb3e0d1f166319b63",
      "ab030daf17b64b13be79b4e745dabad4",
      "1340b39d9076449fa501819d7b18157b",
      "15440a4b253b486db4224c568189c67f",
      "2f8b2509008d486aa5321a166b9f457a",
      "50f7a8ed695142b783bb3b538c70a472",
      "88a28aa40de440c29f573c99e872cfe7",
      "e340411146e9436fb1baf7ef1f7152c6",
      "5b2d972a596443509fcf7076e3b8312b",
      "119e32ad6cd044dba90564e0fc4f478d",
      "801e73cabdf844e5a1be2c01792729d3",
      "29c6eae75c54436da88564c44eed22ae",
      "c24e100fff2e475e9184c1ed53a6eebd",
      "f406263deabf4675aec2f2a4d6b1b941",
      "0e7b5bfb749f4a51bb97ed63d90a6982",
      "38887b9d12064aa6ab7065be9a50f9a9",
      "fb7e7e44b2e644e0871133d24ef86f93",
      "a4d8611de6404cd09a7d2de7ddbfb444",
      "c6ba9e2a078145c88e8736ef94277dce",
      "32c843e9ef87423c889278ceebba8580",
      "23f3daaa2b6c4815a429923639e693bb",
      "bc2cc99db5084f569b000a7bfd01ed44",
      "90d9d9ed2a8b4e15816b7a76a08f9acf",
      "ed36c613567a4150ad692da12ee2e090"
     ]
    },
    "executionInfo": {
     "elapsed": 4444,
     "status": "ok",
     "timestamp": 1756475263023,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "XU77Xt2btvuV",
    "outputId": "739fb648-afb1-4993-afdd-713018b44776"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33dea6f6340465bb0718c7c45a693c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95858aa194c492e93814f1f92ed9651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddf2ef7aaed48d0adcc571c95ae31ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8347d220815f43b684cdc8f4e1d3e0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb4306fd3c24d65b7a2fdb5aed49956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02073d61495d4e74b6af61aacbf14dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c41cead40974e8ca239b7a716c6b6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52a156ca43a49439d743aafa9bd8bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d7af9008d347c0a50e41cc4d52982c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1340b39d9076449fa501819d7b18157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f406263deabf4675aec2f2a4d6b1b941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialise the vector store and embedding functions\n",
    "chroma_client = chromadb.PersistentClient(path=\"/path/to/your/folder\") # put in your current working directory\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "text_collection = chroma_client.get_or_create_collection(name=\"text_collection\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prmaAMJdhohS"
   },
   "source": [
    "### set up Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4851,
     "status": "ok",
     "timestamp": 1756475282151,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "WBb8pZn1hrsm",
    "outputId": "a7e63005-fb03-41f3-c30a-cfb2d1d333eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/297.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/297.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install anthropic --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytHc701ShxV_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import anthropic\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiMz-G3gh4-y"
   },
   "outputs": [],
   "source": [
    "os.environ['ANTHROPIC_API_KEY'] = \"your_api_key_here\" # put in your own API key here\n",
    "GLOBAL_CLIENT = anthropic.Anthropic(\n",
    "\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66-ylIxKgrBr"
   },
   "source": [
    "### set up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6km4wZq9l__t"
   },
   "outputs": [],
   "source": [
    "# control the ratio of data to be indexed\n",
    "def manage_dataset(dataset_path, index_ratio):\n",
    "    random_seed = 42\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    file_names = os.listdir(dataset_path)\n",
    "    random.shuffle(file_names)\n",
    "    # Calculate split size\n",
    "    percentage = int(1/(index_ratio/100))\n",
    "    chunk_size = len(file_names) // percentage  # Calculate base chunk size\n",
    "    remainder = len(file_names) % percentage  # Calculate any remainder to distribute\n",
    "\n",
    "    # Create dictionary to store splits\n",
    "    file_chunks = {}\n",
    "\n",
    "    start_idx = 0\n",
    "    for i in range(percentage):\n",
    "        # Distribute remainder (extra files) to the first few chunks\n",
    "        end_idx = start_idx + chunk_size + (1 if i < remainder else 0)\n",
    "        file_chunks[i] = [os.path.join(dataset_path, file_name) for file_name in file_names[start_idx:end_idx]]\n",
    "        start_idx = end_idx  # Update start index for the next chunk\n",
    "\n",
    "    return file_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm_KWytrHvVM"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/path/to/your/dataset' # put in your local path to the dataset\n",
    "index_ratio = 0.5\n",
    "file_chunks = manage_dataset(dataset_path, index_ratio)\n",
    "print(len(file_chunks[0]))\n",
    "for file in file_chunks[0]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO1kzvydiIzd"
   },
   "source": [
    "### index and save functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdq4qFGMfWBK"
   },
   "outputs": [],
   "source": [
    "def clear_vdb():\n",
    "    global text_collection\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=\"text_collection\")\n",
    "        print(\"Existing collection deleted.\")\n",
    "    except ValueError:\n",
    "        print(\"No existing collection found. Proceeding to create a new one.\")\n",
    "\n",
    "    text_collection = chroma_client.get_or_create_collection(\n",
    "        name=\"text_collection\",\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    print(\"New collection created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR8DYqHzeTQn"
   },
   "outputs": [],
   "source": [
    "def load_pdf_dataset(directory_path):\n",
    "    # Get the paths of all PDF files in the directory.\n",
    "    pdf_files = glob.glob(f\"{directory_path}/*.pdf\")\n",
    "    all_docs = []\n",
    "\n",
    "    for file_path in pdf_files:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "    return loader.load()\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    return loader.load()\n",
    "\n",
    "def chunk_text(text, chunk_size = 500, chunk_overlap = 10):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "\n",
    "def generate_text_embedding(text):\n",
    "    return text_model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVOXGT4kiF3H"
   },
   "source": [
    "### *extract and save locally\n",
    "This block can be run once to extract features and save. For future runnings this block can be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PniS4BuCgVeY"
   },
   "outputs": [],
   "source": [
    "### extract features and save them locally\n",
    "def extract_and_save_locally_withsplit1(save_path, directory_paths, chunk_size = 500, chunk_overlap = 10):\n",
    "    ids = []\n",
    "    uris = []\n",
    "    embeddings = []\n",
    "    image_embeddings = []\n",
    "    text_embeddings = []\n",
    "    global_id = 0\n",
    "\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "\n",
    "\n",
    "    for file_path in directory_paths:\n",
    "        print(f\"Extracted text for {file_path}\")\n",
    "        documents = load_pdf(file_path)\n",
    "        pdf_text = \" \".join([doc.page_content for doc in documents])\n",
    "        split_text = chunk_text(pdf_text, chunk_size = chunk_size, chunk_overlap = 10)\n",
    "        for text in split_text:\n",
    "            text_embedding = generate_text_embedding(text)\n",
    "            ids.append(str(global_id))\n",
    "            uris.append(file_path)\n",
    "            embeddings.append(text_embedding)\n",
    "\n",
    "            global_id += 1\n",
    "            documents.append(text)\n",
    "            metadatas.append({\"image_path\": file_path, \"text_info\": text})\n",
    "\n",
    "\n",
    "    np.savez(save_path, ids = ids, uris = uris, embeddings = embeddings, documents = documents, metadatas = metadatas)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAuJn_YV-Ze0"
   },
   "outputs": [],
   "source": [
    "index_ratio = 0.5\n",
    "dataset_path = '/path/to/your/dataset' # put in your local path to the dataset\n",
    "path1 = '/path/to/save/datasets' # put in the directory where you want to save the extracted features\n",
    "exp_name = f'vectorstore_{index_ratio}%'\n",
    "npz_name = '.npz'\n",
    "save_path = os.path.join(path1, exp_name + npz_name)\n",
    "\n",
    "\n",
    "\n",
    "split_dictionaries = manage_dataset(dataset_path, index_ratio)\n",
    "extract_and_save_locally_withsplit1(save_path, split_dictionaries[0], chunk_size = 500, chunk_overlap = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKjHDDp_slvF"
   },
   "source": [
    "### construct the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkaullOQtZa_"
   },
   "outputs": [],
   "source": [
    "# Add embeddings and other info from specified directories to the vector database.\n",
    "def add_to_vdb3(feature_path, feature_used = 'embeddings'):\n",
    "    \"\"\"\n",
    "    this function is created to make the type of features used in vectorstore a variable\n",
    "    \"\"\"\n",
    "    # documents are not used in later steps, therefore not save to the vectorstore\n",
    "    # ids = ids, uris = uris, embeddings = embeddings, documents = documents, metadatas = metadatas\n",
    "    data = np.load(feature_path, allow_pickle=True)\n",
    "    print(feature_path)\n",
    "    ids = data['ids'].tolist()\n",
    "    uris = data['uris'].tolist()\n",
    "    #documents = data['documents'].tolist()\n",
    "    metadatas = data['metadatas'].tolist()\n",
    "    if feature_used == 'embeddings':\n",
    "        embeddings = data['embeddings']\n",
    "    elif feature_used == 'image_embeddings':\n",
    "        embeddings = data['image_embeddings']\n",
    "    elif feature_used == 'text_embeddings':\n",
    "        embeddings = data['text_embeddings']\n",
    "    #embeddings = data['embeddings']\n",
    "    print(len(ids))\n",
    "    print(len(uris))\n",
    "    print(len(embeddings))\n",
    "\n",
    "\n",
    "    # Add all images to the database at once\n",
    "    if len(ids)!= 0:\n",
    "        text_collection.add(ids=ids, uris=uris, embeddings=embeddings, metadatas = metadatas)\n",
    "        print(f\"Added {len(ids)} text embeddings to the database.\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HtdRn-TIjgB"
   },
   "outputs": [],
   "source": [
    "# construct the vectorstore\n",
    "exp_no_part = '0.5'\n",
    "path1 = '/path/to/the/saved/datasets' # put in the path to the saved features\n",
    "exp_name = f'vectorstore_{exp_no_part}%'\n",
    "#exp_name = 'vectorstore_20perClass'\n",
    "npz_name = '.npz'\n",
    "feature_path = os.path.join(path1, exp_name + npz_name)\n",
    "\n",
    "\n",
    "# Clear the vector database before adding new images\n",
    "clear_vdb()\n",
    "\n",
    "# collect the extracted features from google drive and construct the vectorstore\n",
    "add_to_vdb3(feature_path)\n",
    "\n",
    "\n",
    "# Print the total count of images in the vector database\n",
    "print(\"text embeddings count in the vectorestore:\", text_collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYqA-AVNdVIi"
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvb6VXH3uogJ"
   },
   "outputs": [],
   "source": [
    "def extract_query_features(query):\n",
    "    query_embedding = generate_text_embedding(query)\n",
    "\n",
    "    return query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zml99OLwu3KP"
   },
   "outputs": [],
   "source": [
    "# Retrieve the vector database for similar images.\n",
    "def query_db1(query, results=3, top_k=500):\n",
    "    # the top-k here is not useful\n",
    "    query_features = extract_query_features(query)\n",
    "    try:\n",
    "        all_results = text_collection.query(\n",
    "\n",
    "            query_embeddings=[query_features],\n",
    "            n_results=text_collection.count(),\n",
    "            include=['uris', 'distances']\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying the database: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Filter results\n",
    "    filtered_results = filter_results1(all_results, top_k=results)\n",
    "\n",
    "\n",
    "    retrieved_texts = []\n",
    "    for file_path in filtered_results['uris'][0]:\n",
    "        documents = load_pdf(file_path)\n",
    "        pdf_text = \" \".join([doc.page_content for doc in documents])\n",
    "        retrieved_texts.append(pdf_text)\n",
    "    while len(retrieved_texts) < 3:\n",
    "        retrieved_texts.append('')\n",
    "\n",
    "    return filtered_results, retrieved_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cB3wfuXavPQe"
   },
   "outputs": [],
   "source": [
    "# Filter and sort the retrieved results.\n",
    "def filter_results1(all_results, top_k):\n",
    "\n",
    "    # Combined query results\n",
    "    distances_and_uris_and_ids = list(zip(all_results['distances'][0], all_results['uris'][0], all_results['ids'][0]))\n",
    "\n",
    "\n",
    "    organised_results = [(dist, uri, id) for dist, uri, id in distances_and_uris_and_ids]\n",
    "\n",
    "    # Sort results\n",
    "    sorted_results = sorted(organised_results, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "    # Select top_k results\n",
    "    final_results = sorted_results[:top_k]\n",
    "\n",
    "    # Separate results\n",
    "    sorted_distances = [dist for dist, _, _ in final_results]\n",
    "    sorted_uris = [uri for _, uri, _ in final_results]\n",
    "    sorted_ids = [id for _, _, id in final_results]\n",
    "\n",
    "\n",
    "    return {\n",
    "        'ids': [sorted_ids],\n",
    "        'uris': [sorted_uris],\n",
    "        'distances': [sorted_distances]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-3vKhHITTMM"
   },
   "source": [
    "## Generation: Claude for resultsRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkndnAz9RL2x"
   },
   "outputs": [],
   "source": [
    "# Format the inputs for the prompt template\n",
    "def format_prompt_inputs1(data, user_query, query):\n",
    "    # the data here is the retrieved results\n",
    "    inputs = {}\n",
    "    inputs['query'] = query\n",
    "    inputs['user_query'] = user_query\n",
    "\n",
    "\n",
    "    retrieved_text = ', '.join(data)\n",
    "    inputs['retrieved_info_texts'] = retrieved_text\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_9eVnEqP3YQ"
   },
   "outputs": [],
   "source": [
    "def generate_description_with_rag3(query, user_query):\n",
    "    try:\n",
    "\n",
    "        text_fill = '' # not useful in the function, just a placefiller for consistencies of function callings\n",
    "        results, retrieved_text = query_db1(query, results = 20)\n",
    "        print(f\"Claude Query part is: {query}\")\n",
    "        #print(f\"Retrievals: {results['uris']}\") # to track which files are retrived\n",
    "        print(f\"No. Retrievals: {len(results['uris'][0])}\")\n",
    "\n",
    "\n",
    "        if results is None or len(results['uris'][0]) == 0:\n",
    "            print(f\"Warning: No results retrieved for {query}\")\n",
    "            return \"Unable to generate description due to lack of similar components.\"\n",
    "\n",
    "        prompt_input = format_prompt_inputs1(retrieved_text, user_query, query)\n",
    "        response = claude_vision_chain2(prompt_input)\n",
    "        print(f\"Generations: {response}\")\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate_description_with_rag: {str(e)}\")\n",
    "        print(\"*************************************************************\")\n",
    "        return f\"Error generating description: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "def claude_vision_chain2(prompt_input):\n",
    "\n",
    "    prompt = prompt_input['retrieved_info_texts']\n",
    "    query = prompt_input['query']\n",
    "    user_query = prompt_input['user_query']\n",
    "\n",
    "\n",
    "    message = GLOBAL_CLIENT.messages.create(\n",
    "    #model=\"claude-3-5-sonnet-20241022\", # this model is deprecated\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"\"\"There are models and their information.\"\"\"},\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\"type\": \"text\", \"text\": \"\"\"The perspective we want to focus on about these models are:\"\"\"},\n",
    "                        {\"type\": \"text\", \"text\": query},\n",
    "                        {\"type\": \"text\", \"text\": \"\"\"Please respond to the request:\"\"\"},\n",
    "                        {\"type\": \"text\", \"text\": user_query},\n",
    "                        {\"type\": \"text\", \"text\": \"\"\"Respond with a concise answer in the same phrasing format as in the provided information\"\"\"},\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "    )\n",
    "    output = message.content[0].text\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQju-xaQPe4_"
   },
   "source": [
    "### Level 1 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4630,
     "status": "ok",
     "timestamp": 1756479096456,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "Ur1AwiwLT-qm",
    "outputId": "5b08f851-348a-4629-b43d-e8904fad7f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: what is the volume, surface area and bounding box volume of model_00219733?\n",
      "No. Retrievals: 20\n",
      "Generations: The volume of the model_00219733 is 93000.692 cubic MM.\n",
      "The surface area of the model_00219733 is 20279.800 square MM.\n",
      "The volume of this model_00219733 bounding box is 185203.611 cubic MM.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query1 = 'what is the volume, surface area and bounding box volume of model_00219733?'\n",
    "user_query = \"\"\"information of model_00219733?\n",
    "\"\"\"\n",
    "description = generate_description_with_rag3(query1, user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7kNa4iAJLN4"
   },
   "source": [
    "### Level 2 queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjT_1693Tfu4"
   },
   "outputs": [],
   "source": [
    "def process_query_resultsRecord(query, user_query, generation_no = 10):\n",
    "    files = []\n",
    "    generations = []\n",
    "    files_no = 0\n",
    "\n",
    "\n",
    "    # for claude generation:\n",
    "    description = generate_description_with_rag3(query, user_query)\n",
    "    # for gpt generation:\n",
    "    #description = generate_description_with_rag1(query)\n",
    "\n",
    "    generations.append(description)\n",
    "    return files, generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8641,
     "status": "ok",
     "timestamp": 1756479450894,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "iFeSf9mLVUM2",
    "outputId": "da5716d0-27c6-4ef4-beca-e18d6541fa7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: the volume of the models\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the provided information, here are all the models listed with their volumes in descending order:\n",
      "\n",
      "1. model_00218789 - 77,855,269.847 cubic MM\n",
      "2. model_00214261 - 973,788.103 cubic MM\n",
      "3. model_00217697 - 365,848.342 cubic MM\n",
      "4. model_00219066 - 121,344.748 cubic MM\n",
      "5. model_00219090 - 117,363.577 cubic MM (appears multiple times in the data)\n",
      "6. model_00219733 - 93,000.692 cubic MM\n",
      "7. model_00219880 - 89,501.364 cubic MM\n",
      "8. model_00219579 - 21,885.717 cubic MM (appears multiple times in the data)\n",
      "9. model_00216109 - 16,564.106 cubic MM (appears multiple times in the data)\n",
      "10. model_00219104 - 5,992.963 cubic MM\n",
      "\n",
      "All models in descending order by volume:\n",
      "model_00218789 > model_00214261 > model_00217697 > model_00219066 > model_00219090 > model_00219733 > model_00219880 > model_00219579 > model_00216109 > model_00219104\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# volume prompt\n",
    "query = \"\"\"the volume of the models\n",
    "\"\"\"\n",
    "user_query = \"\"\"list all model, and all models in descending order in terms of their volume\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6471,
     "status": "ok",
     "timestamp": 1756479474425,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "anwVrLq8Yrvt",
    "outputId": "d5d8e12f-9ae8-4c5d-88f9-9872a1609fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: total number of round holes of this model\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the total number of round holes for each model:\n",
      "\n",
      "model_00214261 has 40 round holes\n",
      "model_00219090 has 24 round holes  \n",
      "model_00219579 has 6 round holes\n",
      "model_00217697 has 3 round holes\n",
      "\n",
      "The models in descending order by number of round holes:\n",
      "\n",
      "1. model_00214261 - 40 round holes\n",
      "2. model_00219090 - 24 round holes\n",
      "3. model_00219579 - 6 round holes\n",
      "4. model_00217697 - 3 round holes\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# hole prompt\n",
    "query = \"\"\"total number of round holes of this model\n",
    "\"\"\"\n",
    "user_query = \"\"\"list all models in descending order in terms of their number of round holes\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6657,
     "status": "ok",
     "timestamp": 1756479523460,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "ADQitG5ObU-n",
    "outputId": "887f554b-22d0-4d38-a621-0db7390a23cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: symmetry/symmetrical\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the provided model information, there is only **1 type of symmetry** represented:\n",
      "\n",
      "**No Symmetry:**\n",
      "- All models in the dataset have no symmetry\n",
      "- Examples include: model_00214261, model_00219579, model_00216109, model_00217697, model_00219090, model_00218789, model_00219733, model_00219104, model_00219880, model_00219066\n",
      "\n",
      "Every model in the provided dataset explicitly states \"This model has no symmetry\" and \"The axis of symmetry of this model is None.\"\n",
      "\n",
      "Therefore, there is **1 symmetry type**: No symmetry, with all provided models serving as examples of this category.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# symmetry prompt\n",
    "query = \"\"\"symmetry/symmetrical\n",
    "\"\"\"\n",
    "user_query = \"\"\"How many different symmetries are there? List examples of models for each type of symmetry\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cmr1itfbgoF"
   },
   "source": [
    "### Level 3 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKSLkJ1pbsLb"
   },
   "outputs": [],
   "source": [
    "def process_query_resultsRecord(query, user_query, generation_no = 10):\n",
    "    #results = []\n",
    "    files = []\n",
    "    generations = []\n",
    "    files_no = 0\n",
    "\n",
    "    # for claude generation:\n",
    "    description = generate_description_with_rag3(query, user_query)\n",
    "    # for gpt generation:\n",
    "    #description = generate_description_with_rag1(query)\n",
    "\n",
    "    generations.append(description)\n",
    "\n",
    "    return files, generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12123,
     "status": "ok",
     "timestamp": 1756479136705,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "YswaRe_XUGpB",
    "outputId": "3da93646-0fbb-435a-c576-4223e50b6bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: set the direction/origin/scale/extent/operation to/create a line ending at\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the modelling history of sketch and extrude operations, the models listed are:\n",
      "\n",
      "1. model_00214261\n",
      "2. model_00216109 \n",
      "3. model_00219579\n",
      "4. model_00219733\n",
      "\n",
      "Analyzing the sketch and extrude operations:\n",
      "\n",
      "**model_00219066** (reference model):\n",
      "- Creates circles centered at various coordinates with different radii\n",
      "- Performs extrude operations with extent one values of 0.025400000000000002 and 0.009000000000000001\n",
      "- Uses NewBodyFeatureOperation and JoinFeatureOperation\n",
      "- Creates sketch operations with multiple circles and lines\n",
      "\n",
      "**Most similar model: model_00216109**\n",
      "\n",
      "**Analysis:**\n",
      "- **model_00216109** has the most similar sketch complexity with extensive line and arc creation operations\n",
      "- Both models use similar extrude extent values (0.025 for model_00216109 vs 0.0254 for model_00219066)\n",
      "- Both models perform multiple extrude operations with NewBodyFeatureOperation and CutFeatureOperation\n",
      "- Both models create multiple circles with various radii and coordinate centers\n",
      "- Both models have complex sketch operations involving numerous geometric elements\n",
      "\n",
      "**model_00219579** and **model_00219733** are less similar as they have simpler sketch operations, while **model_00214261** has different operational patterns and fewer geometric elements.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# similarity based on modelling history\n",
    "query = \"\"\"set the direction/origin/scale/extent/operation to/create a line ending at\n",
    "\"\"\"\n",
    "user_query = \"\"\"The records of 'set the direction/origin/scale/extent/operation to...' are the modelling history of extrude operations,\n",
    "and the records of 'createa a line ending at...' are the modelling history of sketch operations.\n",
    "Based on the modelling history of sketch and extrude operations,\n",
    "list all models,\n",
    "and analyse which model is most similar to model_00219066?\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11174,
     "status": "ok",
     "timestamp": 1756479342603,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "RBO2ZL55NuHv",
    "outputId": "c444fe4c-1899-4143-95a9-1bb2e043b1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: models\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the provided information, **model_00219880** appears to be the rarest among all models.\n",
      "\n",
      "This model is distinctive because:\n",
      "\n",
      "- It has only **1 round hole** (with diameter 12.852 MM), making it the model with the fewest holes compared to others that have 9, 24, or 40 holes\n",
      "- It has the simplest modeling history with only **2 sketches and 1 extrude operation**, while other models have 3-4 sketches and multiple extrude operations\n",
      "- Its sketching operations consist of only **4 line endings**, creating basic rectangular geometry, whereas other models have complex combinations of circles, arcs, and numerous line segments\n",
      "- The geometric complexity is minimal compared to models like model_00214261 (40 holes, complex irregular shape) or model_00216109 (9 holes with intricate curved profiles)\n",
      "\n",
      "The combination of minimal geometric features, simplest construction history, and fewest holes makes model_00219880 the most uncommon or rarest design pattern among the provided models.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# rareness\n",
    "query = \"\"\"models\n",
    "\"\"\"\n",
    "user_query = \"\"\"To explain the provided info for different models:\n",
    "The records of 'set the direction/origin/scale/extent/operation to...' are the modelling history of extrude operations,\n",
    "and the records of 'createa a line ending at...' are the modelling history of sketch operations.\n",
    "Other records are about geometric features of the models, such as volume and number of holes.\n",
    "Based on the provided information,\n",
    "which model seems to be the rarest among all models and why?\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13929,
     "status": "ok",
     "timestamp": 1756479390176,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "-sKWM_PcO12R",
    "outputId": "015c1bc6-8fed-4dd5-9ed1-7ac6de3c5929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: models\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the provided information, the models listed are:\n",
      "\n",
      "1. **model_00216109** - A cylindrical part with 9 round holes (diameters: 3.500 MM and 1.500 MM, plus 8.200 MM), volume 16,564.106 cubic MM\n",
      "2. **model_00214261** - A complex part with 40 round holes (various diameters from 5.924 MM to 95.609 MM), volume 973,788.103 cubic MM  \n",
      "3. **model_00219880** - A simple rectangular part with 1 round hole (diameter 12.852 MM), volume 89,501.364 cubic MM\n",
      "4. **model_00219090** - A complex part with 24 round holes (diameters: 8.000 MM and 22.000 MM), volume 117,363.577 cubic MM\n",
      "\n",
      "**Analysis of manufacturing complexity and cost:**\n",
      "\n",
      "**model_00214261** appears to be the most expensive one in terms of manufacturing process because:\n",
      "\n",
      "- **Highest number of holes**: 40 round holes requiring 40 separate drilling/machining operations\n",
      "- **Largest volume**: 973,788.103 cubic MM requires most raw material\n",
      "- **Greatest hole diameter variation**: Diameters ranging from 5.924 MM to 95.609 MM, requiring multiple different drill sizes and potentially different machining processes\n",
      "- **Complex geometry**: Multiple extrude operations and extensive sketch operations with numerous arcs and lines\n",
      "- **Machining time**: The combination of large volume, numerous holes, and varied hole sizes would result in the longest machining time\n",
      "\n",
      "The manufacturing cost factors include: material cost (highest volume), tooling complexity (multiple drill sizes), setup time (numerous operations), and total machining time (40 holes plus complex geometry).\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# manufacturing cost\n",
    "query = \"\"\"models\n",
    "\"\"\"\n",
    "user_query = \"\"\"To explain the provided info for different models:\n",
    "The records of 'set the direction/origin/scale/extent/operation to...' are the modelling history of extrude operations,\n",
    "and the records of 'createa a line ending at...' are the modelling history of sketch operations.\n",
    "Other records are about geometric features of the models, such as volume and number of holes.\n",
    "Based on the provided information,\n",
    "list all models there,\n",
    "and analyse which model seems to be the most expensive one in terms of manufacturing process and why?\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11156,
     "status": "ok",
     "timestamp": 1756479412613,
     "user": {
      "displayName": "S Li",
      "userId": "16183130557533314590"
     },
     "user_tz": -60
    },
    "id": "lhDTJMuSgp9e",
    "outputId": "4656f9ed-2176-47ef-9bed-e7db554d8dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Query part is: models\n",
      "\n",
      "No. Retrievals: 20\n",
      "Generations: Based on the geometric features of the unknown model, I can suggest a possible modeling history:\n",
      "\n",
      "**Model Analysis:**\n",
      "- Volume: 93,000 cubic MM (moderate size)\n",
      "- High curved surface percentage (98.5%) with minimal flat surfaces (1.5%)\n",
      "- No round holes\n",
      "- No symmetry\n",
      "- Moderate Gaussian curvature variance (0.041)\n",
      "\n",
      "**Suggested Modeling History:**\n",
      "\n",
      "The model creates a sketch named Sketch 1 with the following features:\n",
      "The model creates a line ending at (0.0, 0.0).\n",
      "The model creates a line ending at (0.045, 0.0).\n",
      "The model creates a line ending at (0.045, 0.035).\n",
      "The model creates an arc ending at (0.035, 0.045), sweeping 90 degrees clockwise.\n",
      "The model creates a line ending at (0.01, 0.045).\n",
      "The model creates an arc ending at (0.0, 0.035), sweeping 90 degrees clockwise.\n",
      "The model creates a line ending at (0.0, 0.0).\n",
      "\n",
      "The model performs an extrude operation named Extrude 1 with the following parameters:\n",
      "The model sets the direction to (0, 0, 1).\n",
      "The model sets the origin to (0, 0, 0).\n",
      "The model sets the scale to 1.\n",
      "The model sets the extent one to 0.06.\n",
      "The model sets the extent two to 0.0.\n",
      "The model sets the operation to NewBodyFeatureOperation.\n",
      "The model sets the extent type to OneSideFeatureExtentType.\n",
      "\n",
      "The model creates a sketch named Sketch 2 with the following features:\n",
      "The model creates an arc ending at (0.025, 0.015), sweeping 180 degrees clockwise.\n",
      "The model creates an arc ending at (0.025, 0.03), sweeping 180 degrees clockwise.\n",
      "\n",
      "The model performs an extrude operation named Extrude 2 with the following parameters:\n",
      "The model sets the direction to (0, 0, 1).\n",
      "The model sets the origin to (0, 0, 0).\n",
      "The model sets the scale to 1.\n",
      "The model sets the extent one to 0.015.\n",
      "The model sets the extent two to 0.0.\n",
      "The model sets the operation to JoinFeatureOperation.\n",
      "The model sets the extent type to OneSideFeatureExtentType.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# modelling history generation\n",
    "query = \"\"\"models\n",
    "\"\"\"\n",
    "user_query = \"\"\"\n",
    "To explain the provided info for different models:\n",
    "The records of 'set the direction/origin/scale/extent/operation to...' are the modelling history of extrude operations,\n",
    "and the records of 'createa a line ending at...' are the modelling history of sketch operations.\n",
    "Other records are about geometric features of the models, such as volume and number of holes.\n",
    "Now there is the geometric feature description of an unknown model:\n",
    "The volume of the model is 93000 cubic MM.\n",
    "The surface area of the model is 20000 square MM.\n",
    "The volume of this model bounding box is 180000 cubic MM.\n",
    "The variance of the Gaussian curvature of this model is 0.041.\n",
    "The variance of the Mean curvature of this model is 0.000.\n",
    "The flat plane of this model occupies 1.5%.\n",
    "The curved surface of this model occupies 98.5%.\n",
    "The straight edge of this model occupies 58%.\n",
    "The curved edge of this model occupies 42%.\n",
    "This model has no symmetry.\n",
    "The axis of symmetry of this model is None.\n",
    "Total number of round holes of this model is 0.\n",
    "suggest the possible modelling history of this model\n",
    "\"\"\"\n",
    "files, generations = process_query_resultsRecord(query, user_query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
